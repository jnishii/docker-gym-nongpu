{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z4NUv3jjv1Vh"
   },
   "source": [
    "# CartPole by virtual display\n",
    "https://medium.com/@kaleajit27/reinforcement-learning-on-google-colab-9cb2e1ef51e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "UankRExK5-Gp",
    "outputId": "30453326-fa4f-411e-ecfa-22449577484d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Display cmd_param=['Xvfb', '-br', '-nolisten', 'tcp', '-screen', '0', '1400x900x24', ':1001'] cmd=['Xvfb', '-br', '-nolisten', 'tcp', '-screen', '0', '1400x900x24', ':1001'] oserror=None return_code=None stdout=\"None\" stderr=\"None\" timeout_happened=False>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# activate virtual display\n",
    "from pyvirtualdisplay import Display\n",
    "display = Display(visible=0, size=(1400, 900))\n",
    "display.start()\n",
    "\n",
    "# This code creates a virtual display to draw game images on. \n",
    "# If you are running locally, just ignore it\n",
    "import os\n",
    "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\"))==0:\n",
    "    !bash ../xvfb start\n",
    "    %env DISPLAY=:1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w2xLaYy3swOg"
   },
   "source": [
    "# CartPole\n",
    "https://www.kumilog.net/entry/openai-gym-rl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "Episode finished after 14 timesteps\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import gym\n",
    "\n",
    "# 環境の作成\n",
    "env = gym.make('CartPole-v0')\n",
    "\n",
    "# 環境の初期化\n",
    "env.reset()\n",
    "\n",
    "# 1000step回す\n",
    "for t in range(1000):\n",
    "#    env.render()  # 描画\n",
    "    plt.imshow(env.render('rgb_array'))\n",
    "\n",
    "    action = env.action_space.sample()  # ランダムに行動を選択\n",
    "    observation, reward, done, info = env.step(action)  # 行動を実行\n",
    "    if done:\n",
    "        print(\"Episode finished after {} timesteps\".format(t+1))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--episode EPISODE] [--out OUT] [--random]\n",
      "                             [--verbose]\n",
      "                             [env_id]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py:2969: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "from collections import defaultdict\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Q(object):\n",
    "\n",
    "    def __init__(self, action_space, observation_space, bin_size):\n",
    "        self.n_actions = action_space.n\n",
    "        self.observation_space = observation_space\n",
    "        self.config = {\n",
    "            'low_bound': None,\n",
    "            'high_bound': None,\n",
    "            'init_mean': 0.0,\n",
    "            'init_std': 0.0\n",
    "        }\n",
    "        self._observation_dimension = 1\n",
    "        for d in self.observation_space.shape:\n",
    "            self._observation_dimension *= d\n",
    "\n",
    "        if isinstance(bin_size, list):\n",
    "            self._bin_sizes = bin_size\n",
    "        else:\n",
    "            self._bin_sizes = [bin_size] * self._observation_dimension\n",
    "\n",
    "        self._dimension_bins = []\n",
    "        for i, low, high in self._low_high_iter():\n",
    "            b_size = self._bin_sizes[i]\n",
    "            bins = self._make_bins(low, high, b_size)\n",
    "            self._dimension_bins.append(bins)\n",
    "\n",
    "            mean = self.config['init_mean']\n",
    "            std = self.config['init_std']\n",
    "        self.table = defaultdict(lambda: std * np.random.randn(self.n_actions) + mean)\n",
    "\n",
    "    def _make_bins(self, low, high, bin_size):\n",
    "        bins = np.arange(low, high, (float(high) - float(low)) / (bin_size - 2))\n",
    "        if min(bins) < 0 and 0 not in bins:\n",
    "            bins = np.sort(np.append(bins, [0]))\n",
    "        return bins\n",
    "\n",
    "    def _low_high_iter(self):\n",
    "        lows = self.observation_space.low\n",
    "        highs = self.observation_space.high\n",
    "        low_bound = self.config['low_bound']\n",
    "        high_bound = self.config['high_bound']\n",
    "\n",
    "        for i in range(len(lows)):\n",
    "            low = lows[i]\n",
    "            if low_bound is not None:\n",
    "                _low_bound = low_bound if not isinstance(low_bound, list) else low_bound[i]\n",
    "                low = low if _low_bound is None else max(low, _low_bound)\n",
    "\n",
    "            high = highs[i]\n",
    "            if high_bound is not None:\n",
    "                _high_bound = high_bound if not isinstance(high_bound, list) else high_bound[i]\n",
    "                high = high if _high_bound is None else min(high, _high_bound)\n",
    "\n",
    "            yield i, low, high\n",
    "\n",
    "    def observation_to_state(self, observation):\n",
    "        state = 0\n",
    "        unit = max(self._bin_sizes)\n",
    "        for d, o in enumerate(observation.flatten()):\n",
    "            state = state + np.digitize(o, self._dimension_bins[d]) * pow(unit, d)\n",
    "        return state\n",
    "\n",
    "    def values(self, observation):\n",
    "        state = self.observation_to_state(observation)\n",
    "        return self.table[state]\n",
    "\n",
    "\n",
    "class QAgent(object):\n",
    "    def __init__(self, q):\n",
    "        self.config = {\n",
    "            'learning_rate': 0.1,\n",
    "            'init_eps': 0.5,\n",
    "            'gamma': 0.95,\n",
    "            'n_iter': 200}\n",
    "        self.q = q\n",
    "        self.eps = self.config['init_eps']\n",
    "\n",
    "    def act(self, obs):\n",
    "        if self.eps > 0.1:\n",
    "            self.eps *= 0.9999\n",
    "        else:\n",
    "            self.eps = 0.1\n",
    "\n",
    "        if np.random.random() < self.eps:\n",
    "            action = np.random.choice(self.q.n_actions)\n",
    "        else:\n",
    "            action = np.argmax(self.q.values(obs))\n",
    "\n",
    "        return action\n",
    "\n",
    "    def train(self, obs, next_obs, reward, done):\n",
    "        lr = self.config['learning_rate']\n",
    "        gamma = self.config['gamma']\n",
    "\n",
    "        action = self.act(obs)\n",
    "        state = self.q.observation_to_state(obs)\n",
    "\n",
    "        future = 0.0\n",
    "        if not done:\n",
    "            future = np.max(self.q.values(next_obs))\n",
    "\n",
    "        loss = reward + gamma * future - self.q.table[state][action]\n",
    "        self.q.table[state][action] += lr * loss\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "def main(args):\n",
    "    print('Make {} environment'.format(args.env_id))\n",
    "    env = gym.make(args.env_id)\n",
    "\n",
    "    env = gym.wrappers.Monitor(env, directory=args.out, force=True)\n",
    "    env.seed(0)\n",
    "    q = Q(env.action_space, env.observation_space, bin_size=[3, 3, 8, 5])\n",
    "    agent = QAgent(q)\n",
    "\n",
    "    for e in range(args.episode):\n",
    "        obs = env.reset()\n",
    "        R = 0\n",
    "        L = 0\n",
    "        reward = 0\n",
    "        action = env.action_space.sample()\n",
    "        done = False\n",
    "        for t in range(agent.config['n_iter']):\n",
    "            env.render()\n",
    "\n",
    "            if args.random:\n",
    "                action = env.action_space.sample()\n",
    "            else:\n",
    "                action = agent.act(obs)\n",
    "            next_obs, reward, done, _ = env.step(action)\n",
    "            if done:\n",
    "                reward = -200\n",
    "            loss = agent.train(obs, next_obs, reward, done)\n",
    "\n",
    "            if args.verbose:\n",
    "                print('iter: {}'.format(t))\n",
    "                print('\\tobservation: {}'.format(obs))\n",
    "                print('\\taction: {}'.format(action))\n",
    "                print('\\treward: {}'.format(reward))\n",
    "                print('\\tloss: {}'.format(loss))\n",
    "                print('\\teps: {}'.format(agent.eps))\n",
    "\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "            obs = next_obs\n",
    "            R += reward\n",
    "            L += loss\n",
    "        print('Episode {}: total reward={}, average loss={:.4f}'.format(e, R, L/t))\n",
    "\n",
    "    env.close()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(description=None)\n",
    "    parser.add_argument('env_id', nargs='?', default='CartPole-v0',\n",
    "                        help='Select the environment to run')\n",
    "    parser.add_argument('--episode', '-e', type=int, default=100,\n",
    "                        help='Number of episodes')\n",
    "    parser.add_argument('--out', '-o', default='result',\n",
    "                        help='Directory to output the result')\n",
    "    parser.add_argument('--random', '-r', action='store_true')\n",
    "    parser.add_argument('--verbose', '-v', action='store_true')\n",
    "    main(parser.parse_args())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "colab_type": "code",
    "id": "MDeEhrXEsvDo",
    "outputId": "21f69502-955d-41c2-9f9b-1774806ca2a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'agent' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-65cdf6f3467c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mframes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'rgb_array'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;31m#        action=2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'agent' is not defined"
     ]
    }
   ],
   "source": [
    "# 環境の作成\n",
    "env = gym.make('CartPole-v0')\n",
    "\n",
    "frames = []\n",
    "for i in range(3):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    R = 0\n",
    "    t = 0\n",
    "    while not done and t < 200:\n",
    "        frames.append(env.render(mode = 'rgb_array'))\n",
    "        action = agent.act(obs)\n",
    "#        action=2\n",
    "        obs, r, done, _ = env.step(action)\n",
    "        R += r\n",
    "        t += 1\n",
    "    print('test episode:', i, 'R:', R)\n",
    "    agent.stop_episode()\n",
    "env.render()\n",
    "\n",
    "import matplotlib.animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "plt.figure(figsize=(frames[0].shape[1] / 72.0, frames[0].shape[0] / 72.0), dpi = 72)\n",
    "patch = plt.imshow(frames[0])\n",
    "plt.axis('off')\n",
    "animate = lambda i: patch.set_data(frames[i])\n",
    "ani = matplotlib.animation.FuncAnimation(plt.gcf(), animate, frames=len(frames), interval = 50)\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QRGAS7GzsqAk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V61WK3AAwCec"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "openAI_gym.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
