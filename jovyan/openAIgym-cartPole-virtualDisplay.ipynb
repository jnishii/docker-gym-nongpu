{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z4NUv3jjv1Vh"
   },
   "source": [
    "# CartPole by virtual display\n",
    "https://medium.com/@kaleajit27/reinforcement-learning-on-google-colab-9cb2e1ef51e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "UankRExK5-Gp",
    "outputId": "30453326-fa4f-411e-ecfa-22449577484d"
   },
   "outputs": [],
   "source": [
    "# activate virtual display\n",
    "from pyvirtualdisplay import Display\n",
    "display = Display(visible=0, size=(1400, 900))\n",
    "display.start()\n",
    "\n",
    "# This code creates a virtual display to draw game images on. \n",
    "# If you are running locally, just ignore it\n",
    "import os\n",
    "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\"))==0:\n",
    "    !bash ../xvfb start\n",
    "    %env DISPLAY=:1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w2xLaYy3swOg"
   },
   "source": [
    "# CartPole\n",
    "https://www.kumilog.net/entry/openai-gym-rl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "Episode finished after 19 timesteps\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import gym\n",
    "\n",
    "# 環境の作成\n",
    "env = gym.make('CartPole-v0')\n",
    "\n",
    "# 環境の初期化\n",
    "env.reset()\n",
    "\n",
    "# 1000step回す\n",
    "for t in range(1000):\n",
    "#    env.render()  # 描画\n",
    "    plt.imshow(env.render('rgb_array'))\n",
    "\n",
    "    action = env.action_space.sample()  # ランダムに行動を選択\n",
    "    observation, reward, done, info = env.step(action)  # 行動を実行\n",
    "    if done:\n",
    "        print(\"Episode finished after {} timesteps\".format(t+1))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--episode EPISODE] [--out OUT] [--random]\n",
      "                             [--verbose]\n",
      "                             [env_id]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py:2969: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "from collections import defaultdict\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Q(object):\n",
    "\n",
    "    def __init__(self, action_space, observation_space, bin_size):\n",
    "        self.n_actions = action_space.n\n",
    "        self.observation_space = observation_space\n",
    "        self.config = {\n",
    "            'low_bound': None,\n",
    "            'high_bound': None,\n",
    "            'init_mean': 0.0,\n",
    "            'init_std': 0.0\n",
    "        }\n",
    "        self._observation_dimension = 1\n",
    "        for d in self.observation_space.shape:\n",
    "            self._observation_dimension *= d\n",
    "\n",
    "        if isinstance(bin_size, list):\n",
    "            self._bin_sizes = bin_size\n",
    "        else:\n",
    "            self._bin_sizes = [bin_size] * self._observation_dimension\n",
    "\n",
    "        self._dimension_bins = []\n",
    "        for i, low, high in self._low_high_iter():\n",
    "            b_size = self._bin_sizes[i]\n",
    "            bins = self._make_bins(low, high, b_size)\n",
    "            self._dimension_bins.append(bins)\n",
    "\n",
    "            mean = self.config['init_mean']\n",
    "            std = self.config['init_std']\n",
    "        self.table = defaultdict(lambda: std * np.random.randn(self.n_actions) + mean)\n",
    "\n",
    "    def _make_bins(self, low, high, bin_size):\n",
    "        bins = np.arange(low, high, (float(high) - float(low)) / (bin_size - 2))\n",
    "        if min(bins) < 0 and 0 not in bins:\n",
    "            bins = np.sort(np.append(bins, [0]))\n",
    "        return bins\n",
    "\n",
    "    def _low_high_iter(self):\n",
    "        lows = self.observation_space.low\n",
    "        highs = self.observation_space.high\n",
    "        low_bound = self.config['low_bound']\n",
    "        high_bound = self.config['high_bound']\n",
    "\n",
    "        for i in range(len(lows)):\n",
    "            low = lows[i]\n",
    "            if low_bound is not None:\n",
    "                _low_bound = low_bound if not isinstance(low_bound, list) else low_bound[i]\n",
    "                low = low if _low_bound is None else max(low, _low_bound)\n",
    "\n",
    "            high = highs[i]\n",
    "            if high_bound is not None:\n",
    "                _high_bound = high_bound if not isinstance(high_bound, list) else high_bound[i]\n",
    "                high = high if _high_bound is None else min(high, _high_bound)\n",
    "\n",
    "            yield i, low, high\n",
    "\n",
    "    def observation_to_state(self, observation):\n",
    "        state = 0\n",
    "        unit = max(self._bin_sizes)\n",
    "        for d, o in enumerate(observation.flatten()):\n",
    "            state = state + np.digitize(o, self._dimension_bins[d]) * pow(unit, d)\n",
    "        return state\n",
    "\n",
    "    def values(self, observation):\n",
    "        state = self.observation_to_state(observation)\n",
    "        return self.table[state]\n",
    "\n",
    "\n",
    "class QAgent(object):\n",
    "    def __init__(self, q):\n",
    "        self.config = {\n",
    "            'learning_rate': 0.1,\n",
    "            'init_eps': 0.5,\n",
    "            'gamma': 0.95,\n",
    "            'n_iter': 200}\n",
    "        self.q = q\n",
    "        self.eps = self.config['init_eps']\n",
    "\n",
    "    def act(self, obs):\n",
    "        if self.eps > 0.1:\n",
    "            self.eps *= 0.9999\n",
    "        else:\n",
    "            self.eps = 0.1\n",
    "\n",
    "        if np.random.random() < self.eps:\n",
    "            action = np.random.choice(self.q.n_actions)\n",
    "        else:\n",
    "            action = np.argmax(self.q.values(obs))\n",
    "\n",
    "        return action\n",
    "\n",
    "    def train(self, obs, next_obs, reward, done):\n",
    "        lr = self.config['learning_rate']\n",
    "        gamma = self.config['gamma']\n",
    "\n",
    "        action = self.act(obs)\n",
    "        state = self.q.observation_to_state(obs)\n",
    "\n",
    "        future = 0.0\n",
    "        if not done:\n",
    "            future = np.max(self.q.values(next_obs))\n",
    "\n",
    "        loss = reward + gamma * future - self.q.table[state][action]\n",
    "        self.q.table[state][action] += lr * loss\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "def main(args):\n",
    "    print('Make {} environment'.format(args.env_id))\n",
    "    env = gym.make(args.env_id)\n",
    "\n",
    "    env = gym.wrappers.Monitor(env, directory=args.out, force=True)\n",
    "    env.seed(0)\n",
    "    q = Q(env.action_space, env.observation_space, bin_size=[3, 3, 8, 5])\n",
    "    agent = QAgent(q)\n",
    "\n",
    "    for e in range(args.episode):\n",
    "        obs = env.reset()\n",
    "        R = 0\n",
    "        L = 0\n",
    "        reward = 0\n",
    "        action = env.action_space.sample()\n",
    "        done = False\n",
    "        for t in range(agent.config['n_iter']):\n",
    "            env.render()\n",
    "\n",
    "            if args.random:\n",
    "                action = env.action_space.sample()\n",
    "            else:\n",
    "                action = agent.act(obs)\n",
    "            next_obs, reward, done, _ = env.step(action)\n",
    "            if done:\n",
    "                reward = -200\n",
    "            loss = agent.train(obs, next_obs, reward, done)\n",
    "\n",
    "            if args.verbose:\n",
    "                print('iter: {}'.format(t))\n",
    "                print('\\tobservation: {}'.format(obs))\n",
    "                print('\\taction: {}'.format(action))\n",
    "                print('\\treward: {}'.format(reward))\n",
    "                print('\\tloss: {}'.format(loss))\n",
    "                print('\\teps: {}'.format(agent.eps))\n",
    "\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "            obs = next_obs\n",
    "            R += reward\n",
    "            L += loss\n",
    "        print('Episode {}: total reward={}, average loss={:.4f}'.format(e, R, L/t))\n",
    "\n",
    "    env.close()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(description=None)\n",
    "    parser.add_argument('env_id', nargs='?', default='CartPole-v0',\n",
    "                        help='Select the environment to run')\n",
    "    parser.add_argument('--episode', '-e', type=int, default=100,\n",
    "                        help='Number of episodes')\n",
    "    parser.add_argument('--out', '-o', default='result',\n",
    "                        help='Directory to output the result')\n",
    "    parser.add_argument('--random', '-r', action='store_true')\n",
    "    parser.add_argument('--verbose', '-v', action='store_true')\n",
    "    main(parser.parse_args())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "colab_type": "code",
    "id": "MDeEhrXEsvDo",
    "outputId": "21f69502-955d-41c2-9f9b-1774806ca2a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'agent' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-65cdf6f3467c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mframes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'rgb_array'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;31m#        action=2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'agent' is not defined"
     ]
    }
   ],
   "source": [
    "# 環境の作成\n",
    "env = gym.make('CartPole-v0')\n",
    "\n",
    "frames = []\n",
    "for i in range(3):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    R = 0\n",
    "    t = 0\n",
    "    while not done and t < 200:\n",
    "        frames.append(env.render(mode = 'rgb_array'))\n",
    "        action = agent.act(obs)\n",
    "#        action=2\n",
    "        obs, r, done, _ = env.step(action)\n",
    "        R += r\n",
    "        t += 1\n",
    "    print('test episode:', i, 'R:', R)\n",
    "    agent.stop_episode()\n",
    "env.render()\n",
    "\n",
    "import matplotlib.animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "plt.figure(figsize=(frames[0].shape[1] / 72.0, frames[0].shape[0] / 72.0), dpi = 72)\n",
    "patch = plt.imshow(frames[0])\n",
    "plt.axis('off')\n",
    "animate = lambda i: patch.set_data(frames[i])\n",
    "ani = matplotlib.animation.FuncAnimation(plt.gcf(), animate, frames=len(frames), interval = 50)\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QRGAS7GzsqAk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V61WK3AAwCec"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "openAI_gym.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
